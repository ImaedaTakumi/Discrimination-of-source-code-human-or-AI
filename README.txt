一応ファイル毎の説明

以下ソースコード
csv_set.py
solution_python.csvとsolution_python_ai.csvからソースコードを抜き出して
ラベル付けしてsolution_python_processing.csvに保存するコード
また記号を文字列に置換している(変換の対応表は作成してないけどコード内の辞書subdict見ればわかる)
記号の置換に手を加えるならここかな

lstm.py
lstmを実行するコードだがこいつは最新版でないし使えるかわからない
(いつか変えるかも)

tfidf.py
solution_{n}gram.csvからtfidfを求めるコード
コード冒頭のnを1～3の任意の値に変更することでngram.pyで作成したunigram、bigram、trigramで辞書化したファイルに対応
tfidfを辞書順にするか出現順にするかは実行する関数で変更できる。※「ファイルネーム入れて実行するだけ関数一覧」を参照

ngram.py
solution_python_processing.csvからngramを適用したcsvを作成するコード
コード冒頭のnを1～3の任意の値に変更することでunigram、bigram、trigramを作成することが出来る
データの特徴量に条件を加えたいならここかな

以下csvファイル
solution_python.csv
人間が記述したプログラミングコードや問題が入っている(?)csvファイル

solution_python_ai.csv
AIが記述したプログラミングコードや問題が入っている(?)csvファイル
solution_python.csvと同様の問題を取り扱っている

solution_processing.csv
csv_set.pyを用いてsolution_python.csvとsolution_python_ai.csvから
ソースコードを抜き出してラベル付けしたcsvファイル

solution_1gram.csv
ngram.pyを用いて作成したunigramのcsvファイル
ラベルとunigramで取り出された文字列が半角スペースで区切られている

solution_2gram.csv
ngram.pyを用いて作成したbigramのcsvファイル
ラベルとbigramで取り出された文字列が半角スペースで区切られている

solution_3gram.csv
ngram.pyを用いて作成したtrigramのcsvファイル
ラベルとtrigramで取り出された文字列が半角スペースで区切られている

以下成形済みデータ
non_time_series以外は時系列順にtfidfを入れ替えている
Defalut
初期提案手法でのテストデータとトレーニングデータ

non_time_series
tfidf変換時に時系列順にしなかったデータ
それ以外は初期提案手法と同じ

hide_numbers
数値をすべて"num"という文字列に変換した(精度が得られなかったのでunigramのみ)
